{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Домашнее задание к лекции \"Основы веб-скрапинга\"\n",
    "Обязательная часть\n",
    "Вам необходимо написать функцию, которая будет основана на поиске по сайту habr.com. Функция в качестве параметра должна принимать список запросов для поиска (например, ['python', 'анализ данных']) и на основе материалов, попавших в результаты поиска по каждому запросу, возвращать датафрейм вида:\n",
    "\n",
    "<дата> - <заголовок> - <ссылка на материал>\n",
    "В рамках задания предполагается работа только с одной (первой) страницей результатов поисковой выдачи для каждого запроса. Материалы в датафрейме не должны дублироваться, если они попадали в результаты поиска для нескольких запросов из списка.\n",
    "\n",
    "Дополнительная часть (необязательная)\n",
    "Функция из обязательной части задания должна быть расширена следующим образом:\n",
    "\n",
    "кроме списка ключевых слов для поиска необходимо объявить параметр с количеством страниц поисковой выдачи. Т.е. при передаче в функцию аргумента 4 необходимо получить материалы с первых 4 страниц результатов;\n",
    "в датафрейме должны быть столбцы с полным текстом найденных материалов и количеством лайков:\n",
    "<дата> - <заголовок> - <ссылка на материал> - <текст материала> - <количество лайков>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>дата</th>\n",
       "      <th>заголовок</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019-06-24 07:01:14+00:00</td>\n",
       "      <td>How to quickly check out interesting warnings ...</td>\n",
       "      <td>/ru/companies/pvs-studio/articles/457330/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2020-10-12 13:26:57+00:00</td>\n",
       "      <td>Upsetting Opinions about Static Analyzers</td>\n",
       "      <td>/ru/companies/pvs-studio/articles/523114/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2008-12-29 08:54:41+00:00</td>\n",
       "      <td>Mono Migration Analyzer (MoMA)</td>\n",
       "      <td>/ru/articles/48027/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        дата  \\\n",
       "37 2019-06-24 07:01:14+00:00   \n",
       "38 2020-10-12 13:26:57+00:00   \n",
       "39 2008-12-29 08:54:41+00:00   \n",
       "\n",
       "                                            заголовок  \\\n",
       "37  How to quickly check out interesting warnings ...   \n",
       "38          Upsetting Opinions about Static Analyzers   \n",
       "39                     Mono Migration Analyzer (MoMA)   \n",
       "\n",
       "                                         link  \n",
       "37  /ru/companies/pvs-studio/articles/457330/  \n",
       "38  /ru/companies/pvs-studio/articles/523114/  \n",
       "39                        /ru/articles/48027/  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_habr(list1, url='https://habr.com/ru/search/'):\n",
    "   habr = pd.DataFrame()\n",
    "   URL = url\n",
    "   for i in list1:\n",
    "     query = '+'.join(i.split())\n",
    "     params = {\n",
    "        'q': query,\n",
    "        'target_type': 'posts',\n",
    "        'order': 'relevance'\n",
    "          }\n",
    "     req = requests.get(URL, params=params)\n",
    "     soup= BeautifulSoup(req.text)\n",
    "     articles = soup.find_all('div', class_='tm-article-snippet')\n",
    "     for article in articles:\n",
    "       title = article.find('h2').text\n",
    "       link = article.find('a', 'tm-title__link').get('href')\n",
    "       date = pd.to_datetime(article.find('time').get('datetime'))\n",
    "       row = {'дата':date, 'заголовок':title, 'link':link}\n",
    "       habr = pd.concat([habr, pd.DataFrame([row])])\n",
    "   return habr.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "get_habr(['python', 'analyze']).tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>дата</th>\n",
       "      <th>заголовок</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2020-02-13 11:42:06+00:00</td>\n",
       "      <td>PVS-Studio Is Now in Chocolatey: Checking Choc...</td>\n",
       "      <td>/ru/companies/pvs-studio/articles/488204/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2007-09-12 13:59:35+00:00</td>\n",
       "      <td>«Ашманов и партнёры» запустили анализатор поис...</td>\n",
       "      <td>/ru/articles/14024/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2017-02-01 07:00:06+00:00</td>\n",
       "      <td>Как писать кривые запросы с неоптимальным план...</td>\n",
       "      <td>/ru/articles/320916/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         дата  \\\n",
       "152 2020-02-13 11:42:06+00:00   \n",
       "153 2007-09-12 13:59:35+00:00   \n",
       "154 2017-02-01 07:00:06+00:00   \n",
       "\n",
       "                                             заголовок  \\\n",
       "152  PVS-Studio Is Now in Chocolatey: Checking Choc...   \n",
       "153  «Ашманов и партнёры» запустили анализатор поис...   \n",
       "154  Как писать кривые запросы с неоптимальным план...   \n",
       "\n",
       "                                          link  \n",
       "152  /ru/companies/pvs-studio/articles/488204/  \n",
       "153                        /ru/articles/14024/  \n",
       "154                       /ru/articles/320916/  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_habr_pages(list1, pages=4, url='https://habr.com/ru/search/'):\n",
    "    for page in range(1, pages+1):\n",
    "        if page==1:\n",
    "            df1 = get_habr(list1, url=url)\n",
    "        if page>1:\n",
    "            df2 = get_habr(list1, url=f'{url}page{page}/')\n",
    "            df1 = pd.concat([df1, df2], ignore_index=True)\n",
    "    return df1.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "get_habr_pages(['python', 'analyze']).tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
